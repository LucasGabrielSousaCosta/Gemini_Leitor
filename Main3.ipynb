{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import win32com.client\n",
    "import google.generativeai as genai\n",
    "import pyautogui\n",
    "import pyttsx3\n",
    "import time\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNÇÃO PARA CONVERTER AUDIO EM TEXTO\n",
    "POSSIVEIS PROBLEMAS: AJUSTAR O INDICE DO MICROFONE\n",
    "VER MICROFONES DISPONÍVEIS COM: print(sr.Microphone().list_microphone_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_para_texto():\n",
    "    rec = sr.Recognizer()\n",
    "\n",
    "    texto = ''\n",
    "    with sr.Microphone(1) as mic:\n",
    "        rec.adjust_for_ambient_noise(mic)\n",
    "        texto_para_audio('Fale o comando')\n",
    "        audio = rec.listen(mic)\n",
    "        texto = rec.recognize_google(audio,language='pt-BR')\n",
    "\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNÇÃO PARA CONVERTER TEXTO EM AUDIO\n",
    "POSSÍVEIS PROBLEMAS: AJUSTAR O ÍNDICE DA LINGUAGEM\n",
    "VER LISTAS DE LINGUAS INSTALADAS NO SO COM:\n",
    "for voice in voices:\n",
    "    print(voice,voice.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texto_para_audio(texto):\n",
    "\n",
    "        speaker = pyttsx3.init()\n",
    "\n",
    "        voices = speaker.getProperty('voices')\n",
    "\n",
    "        speaker.setProperty('voice',voices[0].id)\n",
    "        rate = speaker.getProperty('rate')\n",
    "        speaker.setProperty('rate', 250)\n",
    "\n",
    "        speaker.say(texto)\n",
    "        speaker.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONECTA COM O GEMINI ATRAVÉS DA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"AIzaSyAg0P014TpRn8YI_dystU90QUT17guj5uk\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNÇÃO PARA PASSAR IMAGEM PARA O GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gemini(path, mime_type=None):\n",
    "  file = genai.upload_file(path, mime_type=mime_type)\n",
    "  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "  return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIGURAÇÃO DO HISTORICO DO GEMINI, DEFINE O PADRÃO DE RESPOSTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file 'teste_gemini.png' as: https://generativelanguage.googleapis.com/v1beta/files/1y5cbthpwhzl\n"
     ]
    }
   ],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "  },\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  safety_settings=safety_settings,\n",
    "  generation_config=generation_config,\n",
    ")\n",
    "\n",
    "image_drive0 = upload_to_gemini(\"teste_gemini.png\", mime_type=\"image/png\")\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": [\n",
    "        \"Você é um assistente para pessoas com deficiência visual, você tem 2 funções:\\n1- Conversar com o usuário(Descrever o que aparece na tela, ensinar o usuário a executar uma ação)\\n2- Executar comandos desejados pelo usuário\\nVocê receberá um input do usuário e deve retornar um output de acordo com as duas categorias, identifique em qual categoria o input se encaixa.\\nNa 1 categoria você deve conversar normalmente com o usuário.\\nNa 2 categoria você deve dar respostas curtas seguindo o padrão apresentado. Não responda com a palavra Output:\",\n",
    "        image_drive0,\n",
    "        \"Você sempre receberá uma imagem.\\nNa categoria 1 você deve ajudar o usuário com base na imagem enviada\\nNa categoria 2 você deve identificar qual elemento o usuário quer interagir e retornar exatamente o nome desse elemento.\",\n",
    "        \"Exemplo categoria 2\\nInput: Abra o google chrome\\n2\\nGoogle Chrome\\n\\nExemplo categoria 2\\n2\\nGoogle Chrome\\n\\nExemplo categoria 2\\ninput:Abre o edge\\n2\\nMicrosoft Edge\\n\\nExemplo categoria 1\\ninput:O que está aparecendo na minha tela?\\n1\\nNessa categoria você deve receber o input do usuário e interpretar a pergunta de acordo com a imagem recebida\\n\\nExemplo categoria 2\\ninput:Abra o docker\\n2\\nDocker Desktop\",\n",
    "      ],\n",
    "    },\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrada_saida():\n",
    "\n",
    "  pergunta = audio_para_texto()\n",
    "\n",
    "  resposta = chat_session.send_message(pergunta)\n",
    "  nome_do_atalho = resposta.text\n",
    "  \n",
    "  pasta_dos_atalhos = r\"C:\\Users\\Public\\Desktop\"\n",
    "  nome_do_atalho = nome_do_atalho.strip() \n",
    "  caminho_do_arquivo = encontrar_atalho_por_nome(pasta_dos_atalhos, str(nome_do_atalho))\n",
    "  \n",
    "  return caminho_do_arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTILIZA O NOME DO ATALHO DIGITADO PELO GEMINI PARA ENCONTRAR O PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_caminho_do_arquivo_do_atalho(caminho_do_atalho):\n",
    "    shell = win32com.client.Dispatch(\"WScript.Shell\")\n",
    "    atalho = shell.CreateShortcut(caminho_do_atalho)\n",
    "    return atalho.TargetPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_atalho_por_nome(pasta, nome_do_atalho):\n",
    "    for arquivo in os.listdir(pasta):\n",
    "        if arquivo.endswith(\".lnk\") and nome_do_atalho in arquivo:\n",
    "            caminho_do_atalho = os.path.join(pasta, arquivo)\n",
    "            try:\n",
    "                caminho_do_arquivo = obter_caminho_do_arquivo_do_atalho(caminho_do_atalho)\n",
    "                return caminho_do_arquivo\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o atalho {caminho_do_atalho}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODIGO PARA ATUALIZAR O PRINT DA TELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tirar_print_da_tela(nome_arquivo):\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    screenshot.save(nome_arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERGUNTA O QUE O USUÁRIO QUER FAZER, PASSA A INSTRUÇÃO PARA O GEMINI, QUE IDENTIFICA O NOME DO ATALHO NA TELA, EXECUTA AS FUNÇÕES PARA ENCONTRAR O PATH E INICIALIZA A APLICAÇÃO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sair\n"
     ]
    }
   ],
   "source": [
    "pergunta = audio_para_texto()\n",
    "print(pergunta)\n",
    "while(pergunta != 'sair'):\n",
    "    chat_session.send_message(image_drive0)\n",
    "    resposta = chat_session.send_message(pergunta)\n",
    "    resposta = resposta.text\n",
    "    print(resposta)\n",
    "    if(resposta[0] == '2'):\n",
    "        nome_do_atalho = resposta[2:]#Os indices anteriores são para categoria e pular linha\n",
    "        \n",
    "        pasta_dos_atalhos = r\"C:\\Users\\Public\\Desktop\"\n",
    "        nome_do_atalho = nome_do_atalho.strip() \n",
    "        caminho_do_arquivo = encontrar_atalho_por_nome(pasta_dos_atalhos, str(nome_do_atalho))\n",
    "        os.startfile(str(caminho_do_arquivo))\n",
    "        time.sleep(5)\n",
    "        tirar_print_da_tela('teste_gemini.png')\n",
    "        image_drive0 = upload_to_gemini(\"teste_gemini.png\", mime_type=\"image/png\")\n",
    "    else:\n",
    "        texto_para_audio(resposta[2:])\n",
    "    pergunta = audio_para_texto()\n",
    "    print(pergunta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
